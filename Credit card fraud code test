# Import required libraries to run the test # 

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn
import scipy
from sklearn.metrics import classification_report,accuracy_score 

# Importing libraries for outlier detection #

from sklearn.ensemble import IsolationForest

from sklearn.svm import OneClassSVM

# Reading the dataset from google drive or comp drive #

from google.colab import drive
drive.mount('/content/drive')
df= pd.read_csv(r"/Users/ayes*****/D******/creditcard.csv")
df.head()

## Data Analysis ##
df.shape

# Checking the null value #
df.isnull().sum()

# Checking the distribution of Normal and fraud cases in our dataset #

fraud_check = pd.value_counts(df['Class'], sort = True)
fraud_check.plot(kind = 'bar', rot=0, color= 'r')
plt.title("Normal and Fraud Distribution")
plt.xlabel("Class")
plt.ylabel("Frequency")
 ## Defining labels to replace our 0 and 1 valuelabels= ['Normal','Fraud']
## mapping those labels 

# What is the shape of the data set for real vs fraud #

fraud_people = df[df['Class']==1]
normal_people = df[df['Class']==0]
normal_people.shape
plt.xticks(range(2), labels)
plt.show()

# What is the shope of Normal and a Fraud Data set # 
fraud_people = df[df['Class']==1]
normal_people = df[df['class']==0]
fraud_people.shape
normal_people.shape

# Finding out the average amount in both datasets # 
fraud_people['Amount'].describe()
normal_people['Amount'].describe()

# Analyze it visually # 

graph, (plot1, plot2) = plt.subplots(2,1,sharex= True)
graph.subtitle('Average amount per class')
bins= 70

plot1.hist(fraud_people['Amount'] , bins = bins)
plot1.set_title('Fraud Amount")

plot2.hist(fraud_people['Amount'] , bins = bins)
plot2.set_title('Normal Amount") 

plt.xlabel('Amount ($) ') 
plt.ylabel('Number of transactions')
plt.yscale('log')
plt.show(); 

# Plotting corr heatmap # 

dr.corr()
plt.figure(figsize=(30,30))
g=sns.heatmap(df.corr(),annot=True)

# Creating Independent and Dependent Features # 

columns = df.columns.tolist()
    ##Making independent features##
columns = [var for var in columns if var not in ["Class"]
    ##Making dependent variable##
target = "Class" 
x= df[columns}
y= df[target]
x.shape 
y.shape
x.head ()  ## Independent variable ##
y.head ()  ## Dependent variable ## 


# Model Building # 

from sklearn.model_selection imoirt train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=42)

# We wil be using the following Models for our Anamoly Detection:  #

Isolation Forest
OneClassSVM 

iso_forest= IsolationForest(n_estimators=100, max_samples=len(x_train),random_state=0, verbose=0)                        
iso_forest.fit(x_train,y_train)
ypred= iso_forest.predict(x_test)
ypred

# Mapping the as an output of 0 and 1 #

ypred[ypred == 1] = 0
ypred[ypred == -1] = 1

# Accuracy and scoring Matrix # 

print(accuracy_score(y_test,ypred))
print(classification_report(y_test,ypred))
from sklearn.metrics import confusion_matrix
confusion_matrix(y_test, ypred)

# We can also print how many errors our model has #

n_errors = (ypred != y_test).sum()
print("Isolation Forest have {} errors.".format(n_errors))

# OneClass SVM #
svm= OneClassSVM(kernel='rbf', degree=3, gamma=0.1,nu=0.05, 
                                         #max_iter=-1)
svm.fit(x_train,y_train)
ypred1= svm.predict(x_test)

# Mapping our results as 0 and 1 #

ypred1[ypred1 == 1] = 0
ypred1[ypred1 == -1] = 1

# Accuracy Score and Matrix #

print(accuracy_score(y_test,ypred))
print(classification_report(y_test,ypred))
from sklearn.metrics import confusion_matrix
confusion_matrix(y_test, ypred)
n_errors = (ypred1 != y_test).sum()
print("SVM have {} errors.".format(n_errors)) 

# Solving the problem with PyCaret Library # 

Installing PyCaret

!pip install pycaret
df= pd.read_csv("creditcard.csv")
df.head()
from pycaret.classification import *
model= setup(data= df, target= 'Class')
compare_models()
random_forest= create_model('rf')

# Obtain Kappa Score if/since  imbalanced#

random_forest= create_model('rf')

# Hypertune the model #

tuned_model= tune_model('random_forest')

# Predictions #

pred_holdout = predict_model(random_forest,data= x_test)
pred_holdout
